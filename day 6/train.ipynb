{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/21], Loss: 1.8641, Accuracy: 33.97%\n",
      "Epoch [2/21], Loss: 1.4669, Accuracy: 50.63%\n",
      "Epoch [3/21], Loss: 1.2326, Accuracy: 58.78%\n",
      "Epoch [4/21], Loss: 1.0357, Accuracy: 65.16%\n",
      "Epoch [5/21], Loss: 0.8605, Accuracy: 71.26%\n",
      "Epoch [6/21], Loss: 0.6764, Accuracy: 77.60%\n",
      "Epoch [7/21], Loss: 0.5344, Accuracy: 82.72%\n",
      "Epoch [8/21], Loss: 0.4210, Accuracy: 85.88%\n",
      "Epoch [9/21], Loss: 0.3180, Accuracy: 89.87%\n",
      "Epoch [10/21], Loss: 0.2515, Accuracy: 91.51%\n",
      "Epoch [11/21], Loss: 0.1908, Accuracy: 93.89%\n",
      "Epoch [12/21], Loss: 0.1530, Accuracy: 94.66%\n",
      "Epoch [13/21], Loss: 0.1191, Accuracy: 96.09%\n",
      "Epoch [14/21], Loss: 0.1269, Accuracy: 95.94%\n",
      "Epoch [15/21], Loss: 0.0933, Accuracy: 96.81%\n",
      "Epoch [16/21], Loss: 0.0916, Accuracy: 97.01%\n",
      "Epoch [17/21], Loss: 0.1036, Accuracy: 96.33%\n",
      "Epoch [18/21], Loss: 0.0746, Accuracy: 97.60%\n",
      "Epoch [19/21], Loss: 0.0469, Accuracy: 98.55%\n",
      "Epoch [20/21], Loss: 0.0588, Accuracy: 97.99%\n",
      "Epoch [21/21], Loss: 0.0926, Accuracy: 97.17%\n",
      "Model saved to plant_disease_resnet.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity \n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 64, blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, blocks=2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, blocks=2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.class_labels = df['folder_name'].unique()\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.class_labels)}\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            image_path = row['image_path']\n",
    "            label = row['folder_name']\n",
    "            label_idx = self.class_to_idx[label]\n",
    "            self.data.append((image_path, label_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_csv = \"train_images.csv\"\n",
    "train_dataset = CustomDataset(csv_file=train_csv, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = ResNet(num_classes=len(train_dataset.class_labels))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 21\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet.pth\")\n",
    "print(f\"Model saved to plant_disease_resnet.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edwar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\edwar\\.cache\\huggingface\\hub\\models--facebook--deit-tiny-patch16-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.3094, Accuracy: 5.76%\n",
      "Model checkpoint saved.\n",
      "Epoch [2/30], Loss: 0.2267, Accuracy: 27.52%\n",
      "Model checkpoint saved.\n",
      "Epoch [3/30], Loss: 0.1947, Accuracy: 40.24%\n",
      "Model checkpoint saved.\n",
      "Epoch [4/30], Loss: 0.1627, Accuracy: 51.04%\n",
      "Model checkpoint saved.\n",
      "Epoch [5/30], Loss: 0.1443, Accuracy: 58.08%\n",
      "Model checkpoint saved.\n",
      "Epoch [6/30], Loss: 0.1262, Accuracy: 64.76%\n",
      "Model checkpoint saved.\n",
      "Epoch [7/30], Loss: 0.1014, Accuracy: 71.92%\n",
      "Model checkpoint saved.\n",
      "Epoch [8/30], Loss: 0.0872, Accuracy: 77.28%\n",
      "Model checkpoint saved.\n",
      "Epoch [9/30], Loss: 0.0847, Accuracy: 78.68%\n",
      "Model checkpoint saved.\n",
      "Epoch [10/30], Loss: 0.0768, Accuracy: 81.08%\n",
      "Model checkpoint saved.\n",
      "Epoch [11/30], Loss: 0.0532, Accuracy: 87.44%\n",
      "Model checkpoint saved.\n",
      "Epoch [12/30], Loss: 0.0450, Accuracy: 90.12%\n",
      "Model checkpoint saved.\n",
      "Epoch [13/30], Loss: 0.0415, Accuracy: 90.48%\n",
      "Model checkpoint saved.\n",
      "Epoch [14/30], Loss: 0.0382, Accuracy: 91.32%\n",
      "Model checkpoint saved.\n",
      "Epoch [15/30], Loss: 0.0360, Accuracy: 91.96%\n",
      "Model checkpoint saved.\n",
      "Epoch [16/30], Loss: 0.0335, Accuracy: 93.12%\n",
      "Model checkpoint saved.\n",
      "Epoch [17/30], Loss: 0.0332, Accuracy: 93.16%\n",
      "Model checkpoint saved.\n",
      "Epoch [18/30], Loss: 0.0288, Accuracy: 94.40%\n",
      "Model checkpoint saved.\n",
      "Epoch [19/30], Loss: 0.0298, Accuracy: 94.12%\n",
      "Epoch [20/30], Loss: 0.0289, Accuracy: 94.00%\n",
      "Epoch [21/30], Loss: 0.0272, Accuracy: 94.56%\n",
      "Model checkpoint saved.\n",
      "Epoch [22/30], Loss: 0.0262, Accuracy: 94.52%\n",
      "Epoch [23/30], Loss: 0.0266, Accuracy: 94.84%\n",
      "Model checkpoint saved.\n",
      "Epoch [24/30], Loss: 0.0256, Accuracy: 95.36%\n",
      "Model checkpoint saved.\n",
      "Epoch [25/30], Loss: 0.0268, Accuracy: 94.60%\n",
      "Epoch [26/30], Loss: 0.0264, Accuracy: 94.92%\n",
      "Epoch [27/30], Loss: 0.0259, Accuracy: 95.04%\n",
      "Epoch [28/30], Loss: 0.0251, Accuracy: 94.96%\n",
      "Epoch [29/30], Loss: 0.0241, Accuracy: 95.52%\n",
      "Model checkpoint saved.\n",
      "Epoch [30/30], Loss: 0.0258, Accuracy: 95.20%\n",
      "Training complete. Best accuracy: 95.52%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class_labels = [\n",
    "    'bacterial_leaf_blight',\n",
    "    'bacterial_leaf_streak',\n",
    "    'bacterial_panicle_blight',\n",
    "    'blast',\n",
    "    'brown_spot',\n",
    "    'dead_heart',\n",
    "    'downy_mildew',\n",
    "    'hispa',\n",
    "    'normal',\n",
    "    'tungro'\n",
    "]\n",
    "\n",
    "# Data transformations with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_paths = self.data['image_path'].values\n",
    "        self.labels = self.data['folder_name'].values\n",
    "        self.transform = transform\n",
    "        self.class_labels = [\n",
    "            'bacterial_leaf_blight',\n",
    "            'bacterial_leaf_streak',\n",
    "            'bacterial_panicle_blight',\n",
    "            'blast',\n",
    "            'brown_spot',\n",
    "            'dead_heart',\n",
    "            'downy_mildew',\n",
    "            'hispa',\n",
    "            'normal',\n",
    "            'tungro'\n",
    "        ]\n",
    "        self.label_map = {label: idx for idx, label in enumerate(self.class_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        folder_name = self.labels[idx]\n",
    "        label = self._get_label_from_folder_name(folder_name)\n",
    "        \n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def _get_label_from_folder_name(self, folder_name):\n",
    "        label_vector = [0] * len(self.class_labels)\n",
    "        if folder_name in self.label_map:\n",
    "            label_vector[self.label_map[folder_name]] = 1\n",
    "        return torch.tensor(label_vector, dtype=torch.float32)\n",
    "\n",
    "# Initialize processor and model\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/deit-tiny-patch16-224\", use_fast=True, trust_remote_code=True)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"facebook/deit-tiny-patch16-224\", trust_remote_code=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(model.classifier.in_features, len(class_labels))\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Dataset and subset loader\n",
    "csv_file = \"train_images.csv\"  \n",
    "full_dataset = CustomImageDataset(csv_file=csv_file, transform=transform)\n",
    "\n",
    "def get_random_subset(dataset, num_samples_per_class):\n",
    "    class_indices = {cls: [] for cls in class_labels}\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        cls_index = torch.argmax(label).item()\n",
    "        class_name = class_labels[cls_index]\n",
    "        class_indices[class_name].append(idx)\n",
    "\n",
    "    subset_indices = []\n",
    "    for cls, indices in class_indices.items():\n",
    "        subset_indices.extend(random.sample(indices, min(len(indices), num_samples_per_class)))\n",
    "\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "subset_dataset = get_random_subset(full_dataset, num_samples_per_class=250)\n",
    "train_loader = DataLoader(subset_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "num_epochs = 30\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=images)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = torch.sigmoid(outputs.logits) > 0.5\n",
    "        correct += (predicted == labels).all(dim=1).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"Model checkpoint saved.\")\n",
    "\n",
    "print(f\"Training complete. Best accuracy: {best_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
